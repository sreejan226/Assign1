{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "code_example_baseline_v2.8.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreejan226/Assign1/blob/main/2.8/code_example_baseline_v2_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "monitor='val_accuracy'\n",
        "epochs=30\n",
        "batch_size=16\n",
        "input_shape=(128, 128, 3) # please resize it to (224,224,3) if you have enough RAM\n",
        "Verbose=True"
      ],
      "metadata": {
        "id": "6DH0gsiwyxgN"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXWocLnz38N"
      },
      "source": [
        "This source code requires a **HIGH RAM** machine.\n",
        "\n",
        "You might need to install this on your system:\n",
        "\n",
        "apt-get install python3-opencv git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQKpflNl7m63",
        "outputId": "c63b8c22-0fa5-48ee-cd38-3656bc027694",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('k'):\n",
        "  !git clone https://github.com/joaopauloschuler/k-neural-api.git k\n",
        "else:\n",
        "  !cd k && git pull\n",
        "\n",
        "!cd k && pip install ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'k'...\n",
            "remote: Enumerating objects: 1838, done.\u001b[K\n",
            "remote: Counting objects: 100% (250/250), done.\u001b[K\n",
            "remote: Compressing objects: 100% (158/158), done.\u001b[K\n",
            "remote: Total 1838 (delta 158), reused 171 (delta 88), pack-reused 1588 (from 1)\u001b[K\n",
            "Receiving objects: 100% (1838/1838), 15.70 MiB | 22.77 MiB/s, done.\n",
            "Resolving deltas: 100% (1271/1271), done.\n",
            "Processing /content/k\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from cai==0.1.7) (2.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from cai==0.1.7) (0.25.2)\n",
            "Requirement already satisfied: opencv-python>=4.1.2.30 in /usr/local/lib/python3.12/dist-packages (from cai==0.1.7) (4.12.0.88)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from cai==0.1.7) (1.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from cai==0.1.7) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.22.0->cai==0.1.7) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.22.0->cai==0.1.7) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.22.0->cai==0.1.7) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.15.0->cai==0.1.7) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.0->cai==0.1.7) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.21.0->cai==0.1.7) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.22.0->cai==0.1.7) (1.17.0)\n",
            "Building wheels for collected packages: cai\n",
            "  Building wheel for cai (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cai: filename=cai-0.1.7-py3-none-any.whl size=61387 sha256=85fe051a7588bcf71c5d143dd45332fa2f6755ab2bcb60ff31f055e19724f920\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-msquypj9/wheels/44/d3/04/5889b6c90ac4bd1e037376d19946cca1579251cf3209e6aed0\n",
            "Successfully built cai\n",
            "Installing collected packages: cai\n",
            "Successfully installed cai-0.1.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FWmCCX96ndE",
        "outputId": "50fe93f1-f5b6-4417-f2d1-8c1884041a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import sys\n",
        "print(\"Python version\")\n",
        "print (sys.version)\n",
        "print(\"Version info.\")\n",
        "print (sys.version_info)\n",
        "\n",
        "import skimage\n",
        "print('skimage version',  skimage.__version__)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import sys\n",
        "import cai\n",
        "import cai.datasets\n",
        "import cai.densenet\n",
        "import cai.util\n",
        "import cai.models"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version\n",
            "3.12.11 (main, Jun  4 2025, 08:56:18) [GCC 11.4.0]\n",
            "Version info.\n",
            "sys.version_info(major=3, minor=12, micro=11, releaselevel='final', serial=0)\n",
            "skimage version 0.25.2\n",
            "2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WqdOtor61VZ",
        "outputId": "aa46e56f-4228-463c-c145-5e58ca12d836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "url_zip_file=\"https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/file_downloaded\"\n",
        "local_zip_file=\"plant_leaf.zip\"\n",
        "expected_folder_name=\"plant_leaf\"\n",
        "cai.datasets.download_zip_and_extract(\n",
        "    url_zip_file=url_zip_file, local_zip_file=local_zip_file,\n",
        "    expected_folder_name=expected_folder_name, Verbose=Verbose)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading:  https://data.mendeley.com/public-files/datasets/tywbtsjrjv/files/d5652a28-c1d8-4b76-97f3-72fb80f94efc/file_downloaded  to  plant_leaf.zip\n",
            "Decompressing into:  plant_leaf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yn9mmLAxvlK"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2LGtzGBx5IR",
        "outputId": "c95c89e5-eb99-4228-95cb-f6239bdd0aed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!rm -r plant_leaf/Plant_leave_diseases_dataset_without_augmentation/Background_without_leaves -R\n",
        "data_dir = \"plant_leaf/Plant_leave_diseases_dataset_without_augmentation/\"\n",
        "print(os.listdir(data_dir))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Strawberry___healthy', 'Potato___Early_blight', 'Tomato___Leaf_Mold', 'Tomato___Spider_mites Two-spotted_spider_mite', 'Peach___healthy', 'Pepper,_bell___Bacterial_spot', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 'Grape___healthy', 'Cherry___Powdery_mildew', 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 'Corn___healthy', 'Potato___healthy', 'Potato___Late_blight', 'Pepper,_bell___healthy', 'Peach___Bacterial_spot', 'Raspberry___healthy', 'Tomato___Septoria_leaf_spot', 'Tomato___Bacterial_spot', 'Blueberry___healthy', 'Apple___Cedar_apple_rust', 'Tomato___Early_blight', 'Tomato___healthy', 'Grape___Esca_(Black_Measles)', 'Orange___Haunglongbing_(Citrus_greening)', 'Tomato___Target_Spot', 'Apple___Black_rot', 'Tomato___Tomato_mosaic_virus', 'Apple___Apple_scab', 'Soybean___healthy', 'Cherry___healthy', 'Corn___Northern_Leaf_Blight', 'Tomato___Late_blight', 'Grape___Black_rot', 'Apple___healthy', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Strawberry___Leaf_scorch', 'Corn___Common_rust', 'Squash___Powdery_mildew']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUfiL_BgqOct"
      },
      "source": [
        "def compiled_two_path_inception_v3(\n",
        "  classes=1000,\n",
        "  input_shape=input_shape,\n",
        "  two_paths_first_block=False,\n",
        "  two_paths_second_block=False,\n",
        "  max_mix_idx=10):\n",
        "  base_model = cai.models.two_path_inception_v3(\n",
        "    include_top=False,\n",
        "    weights=None,\n",
        "    input_shape=input_shape,\n",
        "    pooling=None,\n",
        "    two_paths_first_block=two_paths_first_block,\n",
        "    two_paths_second_block=two_paths_second_block,\n",
        "    max_mix_idx=max_mix_idx)\n",
        "  x = base_model.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(38, name='preprediction')(x)\n",
        "  predictions = Activation('softmax',name='prediction')(x)\n",
        "  model = Model(inputs=base_model.input, outputs=predictions)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "  optimizer = 'sgd',\n",
        "  metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_1lHVDc082Z",
        "outputId": "a5db26bb-fb6c-4799-95a0-ba409968fb3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_x, val_x, test_x, train_y, val_y, test_y, classweight, classes = cai.datasets.load_images_from_folders(seed=7, root_dir=data_dir, lab=False,\n",
        "  verbose=Verbose, bipolar=False, base_model_name='plant_leaf',\n",
        "  training_size=0.6, validation_size=0.2, test_size=0.2,\n",
        "  target_size=(input_shape[0],input_shape[1]),\n",
        "  has_training=True, has_validation=True, has_testing=True,\n",
        "  smart_resize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading  38  classes.\n",
            "smart resize is enabled.\n",
            "loading train images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UosoQy_c1_4M"
      },
      "source": [
        "print(train_x.shape,val_x.shape,test_x.shape)\n",
        "print(train_y.shape,val_y.shape,test_y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-q_V3dJ3BhT"
      },
      "source": [
        "for max_mix_idx in [5]: # range(-1,10,1):\n",
        "    basefilename = 'Schuler-baseline-v2.8-'+str(max_mix_idx)\n",
        "    print('Running: '+basefilename)\n",
        "    model = compiled_two_path_inception_v3(\n",
        "      classes=38,\n",
        "      input_shape=input_shape,\n",
        "      two_paths_first_block=False,\n",
        "      two_paths_second_block=False,\n",
        "      max_mix_idx=max_mix_idx)\n",
        "    best_result_file_name = basefilename+'-best-result.hdf5'\n",
        "    save_best = tensorflow.keras.callbacks.ModelCheckpoint(\n",
        "      filepath=best_result_file_name,\n",
        "      monitor=monitor,\n",
        "      verbose=1,\n",
        "      save_best_only=True,\n",
        "      save_weights_only=False,\n",
        "      mode='max',\n",
        "      save_freq='epoch')\n",
        "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size,\n",
        "      validation_data=(val_x,val_y),\n",
        "      callbacks=[save_best],\n",
        "      class_weight = classweight\n",
        "    )\n",
        "    print('Testing Last Model: '+basefilename)\n",
        "    evaluated = model.evaluate(test_x,test_y)\n",
        "    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "      print(name,metric)\n",
        "    print('Best Model Results: '+basefilename)\n",
        "    model = tensorflow.keras.models.load_model(best_result_file_name, custom_objects={'CopyChannels': cai.layers.CopyChannels})\n",
        "    evaluated = model.evaluate(test_x,test_y)\n",
        "    for metric, name in zip(evaluated,[\"loss\",\"acc\",\"top 5 acc\"]):\n",
        "      print(name,metric)\n",
        "    print('Finished: '+basefilename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}